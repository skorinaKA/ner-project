{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers evaluate seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка датасетка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Для обозначения названий гор в тексте мы используем набор данных [Few-NERD][1], который доступен на Kaggle[2] и huggingface[3]. Мы используем supervised-часть этого набора данных</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da1e2c502c445788016695666110d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542a970bf10b4c28b50b05b92b4d2bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea799246048a47b2917beef2bd2a1da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 131766\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 18823\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 37647\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fewnerd = load_dataset('json', data_files={\n",
    "    'train': '../fewnerd/supervised/train.json',\n",
    "    'val': '../fewnerd/supervised/dev.json',\n",
    "    'test': '../fewnerd/supervised/test.json',\n",
    "})\n",
    "fewnerd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Загрузка списка тегов</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'O', '1': 'art', '2': 'building', '3': 'event', '4': 'location', '5': 'organization', '6': 'other', '7': 'person', '8': 'product'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'art-broadcastprogram',\n",
       " '2': 'art-film',\n",
       " '3': 'art-music',\n",
       " '4': 'art-other',\n",
       " '5': 'art-painting',\n",
       " '6': 'art-writtenart',\n",
       " '7': 'building-airport',\n",
       " '8': 'building-hospital',\n",
       " '9': 'building-hotel',\n",
       " '10': 'building-library',\n",
       " '11': 'building-other',\n",
       " '12': 'building-restaurant',\n",
       " '13': 'building-sportsfacility',\n",
       " '14': 'building-theater',\n",
       " '15': 'event-attack/battle/war/militaryconflict',\n",
       " '16': 'event-disaster',\n",
       " '17': 'event-election',\n",
       " '18': 'event-other',\n",
       " '19': 'event-protest',\n",
       " '20': 'event-sportsevent',\n",
       " '21': 'location-GPE',\n",
       " '22': 'location-bodiesofwater',\n",
       " '23': 'location-island',\n",
       " '24': 'location-mountain',\n",
       " '25': 'location-other',\n",
       " '26': 'location-park',\n",
       " '27': 'location-road/railway/highway/transit',\n",
       " '28': 'organization-company',\n",
       " '29': 'organization-education',\n",
       " '30': 'organization-government/governmentagency',\n",
       " '31': 'organization-media/newspaper',\n",
       " '32': 'organization-other',\n",
       " '33': 'organization-politicalparty',\n",
       " '34': 'organization-religion',\n",
       " '35': 'organization-showorganization',\n",
       " '36': 'organization-sportsleague',\n",
       " '37': 'organization-sportsteam',\n",
       " '38': 'other-astronomything',\n",
       " '39': 'other-award',\n",
       " '40': 'other-biologything',\n",
       " '41': 'other-chemicalthing',\n",
       " '42': 'other-currency',\n",
       " '43': 'other-disease',\n",
       " '44': 'other-educationaldegree',\n",
       " '45': 'other-god',\n",
       " '46': 'other-language',\n",
       " '47': 'other-law',\n",
       " '48': 'other-livingthing',\n",
       " '49': 'other-medical',\n",
       " '50': 'person-actor',\n",
       " '51': 'person-artist/author',\n",
       " '52': 'person-athlete',\n",
       " '53': 'person-director',\n",
       " '54': 'person-other',\n",
       " '55': 'person-politician',\n",
       " '56': 'person-scholar',\n",
       " '57': 'person-soldier',\n",
       " '58': 'product-airplane',\n",
       " '59': 'product-car',\n",
       " '60': 'product-food',\n",
       " '61': 'product-game',\n",
       " '62': 'product-other',\n",
       " '63': 'product-ship',\n",
       " '64': 'product-software',\n",
       " '65': 'product-train',\n",
       " '66': 'product-weapon'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../fewnerd/id2coarse_tags.json\", \"r\") as f:\n",
    "    id2coarse_tag = json.load(f)\n",
    "print(id2coarse_tag)\n",
    "    \n",
    "with open(\"../fewnerd/id2fine_tags.json\", \"r\") as f:\n",
    "    id2fine_tag = json.load(f)\n",
    "id2fine_tag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, [46, 75, 98, 138, 284])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOUTAIN_TAG = 24\n",
    "\n",
    "rows_with_mountain_tag = [i for i, row in enumerate(fewnerd[\"train\"][\"fine_tags\"]) if MOUTAIN_TAG in row]\n",
    "len(rows_with_mountain_tag), rows_with_mountain_tag[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Примеры данных обучающей выборки датасета:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'Eighth', 'Army', 'began', 'to', 'attack', 'Italian', 'units', ',', 'located', 'using', 'information', 'from', 'Ultra', ',', 'at', 'Ruweisat', 'Ridge', 'and', 'from', 'again', 'at', 'Tel', 'El', 'Eisa', 'on', '22', 'July', 'and', 'Miteirya', 'Ridge', 'after', 'which', 'another', 'lull', 'fell', '.'], 'coarse_tags': [0, 5, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0], 'fine_tags': [0, 32, 32, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 21, 21, 21, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 0, 0], 'id': '46'} \n",
      "\n",
      "{'tokens': ['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'], 'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0], 'fine_tags': [0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0], 'id': '75'} \n",
      "\n",
      "{'tokens': ['Mount', 'Diablo', 'has', 'inspired', 'many', 'artists', 'and', 'writers', '.'], 'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 24, 0, 0, 0, 0, 0, 0, 0], 'id': '98'} \n",
      "\n",
      "{'tokens': ['K2', 'is', 'further', 'north', 'than', 'the', 'Himalayan', 'mountains', 'so', 'the', 'climate', 'is', 'colder', ';', 'the', 'Karakoram', 'range', 'is', 'wider', 'than', 'the', 'Himalayan', 'so', 'more', 'ice', 'and', 'snow', 'is', 'trapped', 'there', '.'], 'coarse_tags': [4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': '138'} \n",
      "\n",
      "{'tokens': ['The', 'North', 'Lyell', 'Mine', ',', 'scene', 'of', 'the', '1912', 'North', 'Mount', 'Lyell', 'Disaster', 'was', 'at', 'its', 'northernmost', 'end', ',', 'on', 'the', 'slopes', 'of', 'Mount', 'Lyell', '.'], 'coarse_tags': [0, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0], 'fine_tags': [0, 11, 11, 11, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0], 'id': '284'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in fewnerd[\"train\"].select(rows_with_mountain_tag[:5]):\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Замена тегов, отличных от нужных тегов на 0, нужных тегов на 1 и удаление дополнительных столбцов из новых наборов данных</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9b952995b2408b9c327e0b6e4d73b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a02ea826ef42fd950c156bd9cd42af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2646d67d294e4b8c3a21bc768b2694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tag_map(tag):\n",
    "    return 1 if tag == MOUTAIN_TAG else 0\n",
    "\n",
    "def tag_list_map(tag_list):\n",
    "    return list(map(tag_map, tag_list))\n",
    "\n",
    "def fine_tags_map(examples):\n",
    "    examples[\"mountain_tags\"] = list(map(tag_list_map, examples[\"fine_tags\"]))    \n",
    "    return examples\n",
    "    \n",
    "fewnerd_mountains = fewnerd.map(fine_tags_map, remove_columns=[\"coarse_tags\", \"fine_tags\", \"id\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Вычисление количества меток нужного тега в обработанных наборах данных и их доля в датасете</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset - mountain tags: 4500, O tags: 3223038, proportion: 0.0013961982452580454\n",
      "val   dataset - mountain tags: 734, O tags: 462386, proportion: 0.0015874183041874104\n",
      "test  dataset - mountain tags: 1366, O tags: 919688, proportion: 0.0014852863144892616\n"
     ]
    }
   ],
   "source": [
    "def print_mountain_dataset_stat(name, dataset):\n",
    "    mountain_tags_num = 0\n",
    "    tags_num = 0\n",
    "    for tags in dataset[\"mountain_tags\"]:\n",
    "        mountain_tags_num += sum(tags)\n",
    "        tags_num += len(tags)\n",
    "    o_tags_num = tags_num - mountain_tags_num\n",
    "    print(f\"{name:<5} dataset - mountain tags: {mountain_tags_num}, O tags: {o_tags_num}, proportion: {mountain_tags_num/o_tags_num}\")\n",
    "\n",
    "for k in fewnerd_mountains.keys():\n",
    "    print_mountain_dataset_stat(k, fewnerd_mountains[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Загрузка токенизатора DistilBERT для предварительной обработки поля токенов.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bbfe9b510745368717c4ec422f8520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e23e753d0c45a682d13b67bd9c1bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee17f0ce9c5b4a839819e98c197c28cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66ab691d8904e109bd442378749f49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Пример работы токенизатора:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'] \n",
      "\n",
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
      "\n",
      "['[CLS]', 'though', 'only', 'in', 'length', ',', 'the', 'sal', '##aman', '##der', 'glacier', 'is', 'about', 'wide', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example = fewnerd_mountains[\"train\"][\"tokens\"][75]\n",
    "tokenized_input = tokenizer(example, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "print(example, \"\\n\")\n",
    "print(tokenized_input, \"\\n\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Токенизатор добавляет некоторые специальные токены, а токенизация вложенных слов приводит к несоответствию между вводимыми данными и метками. Одно слово, соответствующее одной метке, теперь можно разделить на два вложенных слова. Мы перестраиваем маркеры и метки и удаляем лишние столбцы из новых наборов данных.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f651ce5e8e8143319b3518bcf023862e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b19cf860ce4aab8ae489e298b074be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77e1713e8034c36acedbd7e9a1f8697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Значение, которое игнорируется и не влияет на градиент в CrossEntropyLoss\n",
    "IGNORE_INDEX = -100 \n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"mountain_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) # Сопоставление токенов с их соответствующим словом\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(IGNORE_INDEX) \n",
    "            else:\n",
    "                label_ids.append(label[word_idx]) \n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "fewnerd_mountains = fewnerd_mountains.map(tokenize_and_align_labels, remove_columns=[\"tokens\", \"mountain_tags\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Пример обработанного набора данных:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(fewnerd_mountains[\"train\"][75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Настройка средства сопоставления данных</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Прежде чем приступить к обучению модели, создаем список меток и словари с идентификаторами меток и самими метками</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'location-mountain'] \n",
      "\n",
      "{0: 'O', 1: 'location-mountain'} \n",
      "\n",
      "{'O': 0, 'location-mountain': 1}\n"
     ]
    }
   ],
   "source": [
    "label_list = [id2fine_tag[str(0)], id2fine_tag[str(MOUTAIN_TAG)]]\n",
    "print(label_list, \"\\n\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "print(id2label, \"\\n\")\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Загружаем модель DistilBERT с помощью AutoModelForTokenClassification, указав количество ожидаемых меток и их соответствие</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e425bd02cd4d958db6076a6f832719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Создаем функцию, которая вычисляет метрики на основе прогнозов и меток, игнорируя метки для специальных токенов</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f623d67531be40a491c6b258ece745ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != IGNORE_INDEX]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [ [label_list[l] for l in label if l != IGNORE_INDEX] for label in labels ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)    \n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Из-за разницы в количестве нужных и обычных тегов в наборах данных следует использовать весовые коэффициенты классов в функции потерь. Для этого нам нужно доработать класс Trainer.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def __init__(self, tag_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tag_weights = tag_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, num_items_in_batch = None, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")       \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')        \n",
    "        \n",
    "        # Compute custom loss\n",
    "        weight=torch.tensor(self.tag_weights)\n",
    "        if torch.cuda.is_available():\n",
    "           weight = weight.cuda()\n",
    "        #    print(\"GPU Activate\")\n",
    "        loss_fun = torch.nn.CrossEntropyLoss(weight)\n",
    "        loss = loss_fun(logits.view(-1, model.config.num_labels), labels.view(-1))        \n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Задаем параметры для обучения модели с помощью экземпляра CustomTrainer, обучаем модель и оцениваем ее на тестовом наборе данных</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_965/1443336891.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Loading settings from /root/.config/wandb/settings\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for http://wandb:8080 from /root/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m-skorinaka\u001b[0m to \u001b[32mhttp://wandb:8080\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebooks/wandb/run-20260213_220426-brmf80vo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://wandb:8080/-skorinaka/huggingface/runs/brmf80vo' target=\"_blank\">../train_output</a></strong> to <a href='http://wandb:8080/-skorinaka/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://wandb:8080/-skorinaka/huggingface' target=\"_blank\">http://wandb:8080/-skorinaka/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://wandb:8080/-skorinaka/huggingface/runs/brmf80vo' target=\"_blank\">http://wandb:8080/-skorinaka/huggingface/runs/brmf80vo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123540' max='123540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123540/123540 9:15:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.463736</td>\n",
       "      <td>0.574932</td>\n",
       "      <td>0.513382</td>\n",
       "      <td>0.998539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.023716</td>\n",
       "      <td>0.503632</td>\n",
       "      <td>0.566757</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.998656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>0.561364</td>\n",
       "      <td>0.673025</td>\n",
       "      <td>0.612144</td>\n",
       "      <td>0.998711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.555858</td>\n",
       "      <td>0.604444</td>\n",
       "      <td>0.998838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.612987</td>\n",
       "      <td>0.643052</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.998698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.046920</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.607629</td>\n",
       "      <td>0.630835</td>\n",
       "      <td>0.998783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.509537</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.998726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.080655</td>\n",
       "      <td>0.699324</td>\n",
       "      <td>0.564033</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.998862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.064416</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.580381</td>\n",
       "      <td>0.644478</td>\n",
       "      <td>0.998862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.053328</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.596730</td>\n",
       "      <td>0.642229</td>\n",
       "      <td>0.998816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.566757</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>0.998765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.090559</td>\n",
       "      <td>0.746212</td>\n",
       "      <td>0.536785</td>\n",
       "      <td>0.624406</td>\n",
       "      <td>0.998741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.564033</td>\n",
       "      <td>0.643857</td>\n",
       "      <td>0.998789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070165</td>\n",
       "      <td>0.715655</td>\n",
       "      <td>0.610354</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.998831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073959</td>\n",
       "      <td>0.716172</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>0.647761</td>\n",
       "      <td>0.998822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2353' max='2353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2353/2353 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location-mountain seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06592143326997757,\n",
       " 'eval_precision': 0.6784565916398714,\n",
       " 'eval_recall': 0.6196769456681351,\n",
       " 'eval_f1': 0.6477359938603223,\n",
       " 'eval_accuracy': 0.998946312694164,\n",
       " 'eval_runtime': 65.2888,\n",
       " 'eval_samples_per_second': 576.622,\n",
       " 'eval_steps_per_second': 36.04,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "tag_weights = [0.1, 1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../train_output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tag_weights=tag_weights,\n",
    "    args=training_args,\n",
    "    train_dataset=fewnerd_mountains[\"train\"],\n",
    "    eval_dataset=fewnerd_mountains[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate(fewnerd_mountains[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Сохраняем модель и токенизатор в директории</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/fewnerd-mountains-model/tokenizer_config.json',\n",
       " '../models/fewnerd-mountains-model/special_tokens_map.json',\n",
       " '../models/fewnerd-mountains-model/vocab.txt',\n",
       " '../models/fewnerd-mountains-model/added_tokens.json',\n",
       " '../models/fewnerd-mountains-model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"../models/fewnerd-mountains-model\"\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Метрики модели для распознавания сущностей в тексте аналогичны метрикам BERT для всех категорий именованных сущностей в контролируемом наборе данных [Few-NERD](http://ningding97.github.io/fewnerd). Таким образом, изменяя параметры обучения, мы можем немного повысить производительность модели, но более значительного улучшения можно добиться, только заменив базовую модель DistilBERT на другую языковую модель, например RoBERTa или XLNet.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Загружаем модель и токенизатор по указанному пути и определяем функцию, которая помечает каждое слово в тексте нужным тегом или тегом “O”</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"../models/fewnerd-mountains-model\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Возвращает список пар слов и тегов на основе модели и токенизатора\n",
    "def get_word_tag_list(text):    \n",
    "    tokenized_input = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "    # Вычисляет список прогнозируемых тегов для всех токенов на основе модели\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokenized_input).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    predicted_tags = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "\n",
    "    # Список, сопоставляющий идентификаторы токенов с идентификаторами слов\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    \n",
    "    # Получение списка\n",
    "    word_to_token_ids = []\n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is not None:\n",
    "            if word_id >= len(word_to_token_ids):\n",
    "                word_to_token_ids.append([])\n",
    "            word_to_token_ids[word_id].append(idx)\n",
    "\n",
    "    # Список пар слов и тэгов\n",
    "    word_tag_list = []    \n",
    "    for word_id in range(len(word_to_token_ids)):\n",
    "        span = tokenized_input.word_to_chars(word_id)\n",
    "        word = text[span.start:span.end]\n",
    "        \n",
    "        token_id = word_to_token_ids[word_id][0]\n",
    "        tag = predicted_tags[token_id]       \n",
    "        \n",
    "        word_tag_list.append((word, tag))\n",
    "\n",
    "    return word_tag_list     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Функция выводящая результат</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the model output\n",
    "def print_word_tag_list(text):\n",
    "    word_tag_list = get_word_tag_list(text)\n",
    "    for p in word_tag_list:\n",
    "        print(f\"{p[0]} : {p[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">В итоге можно проверить выходные данные текста:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : O\n",
      "Golden : O\n",
      "State : O\n",
      "Warriors : O\n",
      "are : O\n",
      "an : O\n",
      "American : O\n",
      "professional : O\n",
      "basketball : O\n",
      "team : O\n",
      "based : O\n",
      "in : O\n",
      "San : O\n",
      "Francisco : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "text = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : O\n",
      "Mont : location-mountain\n",
      "Blanc : location-mountain\n",
      "massif : O\n",
      "is : O\n",
      "popular : O\n",
      "for : O\n",
      "outdoor : O\n",
      "activities : O\n",
      "like : O\n",
      "hiking : O\n",
      ", : O\n",
      "climbing : O\n",
      ", : O\n",
      "trail : O\n",
      "running : O\n",
      "and : O\n",
      "winter : O\n",
      "sports : O\n",
      "like : O\n",
      "skiing : O\n",
      ", : O\n",
      "and : O\n",
      "snowboarding : O\n",
      ". : O\n",
      "The : O\n",
      "most : O\n",
      "popular : O\n",
      "climbing : O\n",
      "route : O\n",
      "to : O\n",
      "the : O\n",
      "summit : O\n",
      "of : O\n",
      "Mont : location-mountain\n",
      "Blanc : location-mountain\n",
      "is : O\n",
      "the : O\n",
      "Goûter : O\n",
      "Route : O\n",
      ", : O\n",
      "which : O\n",
      "typically : O\n",
      "takes : O\n",
      "two : O\n",
      "days : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" \n",
    "The Mont Blanc massif is popular for outdoor activities like hiking, climbing, trail running and winter sports like skiing, and snowboarding.\n",
    "The most popular climbing route to the summit of Mont Blanc is the Goûter Route, which typically takes two days.\n",
    "\"\"\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mont : O\n",
      "Blanc : O\n",
      "is : O\n",
      "a : O\n",
      "beautiful : O\n",
      "rooftop : O\n",
      "cafe : O\n",
      ". : O\n"
     ]
    }
   ],
   "source": [
    "text = \"Mont Blanc is a beautiful rooftop cafe.\"\n",
    "print_word_tag_list(text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1383328,
     "sourceId": 2297849,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
