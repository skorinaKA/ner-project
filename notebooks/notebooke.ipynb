{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers evaluate seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">For the indentification of mountain names inside the text we use [Few-NERD](http://ningding97.github.io/fewnerd) dataset, which is also available at [Kaggle](http://www.kaggle.com/datasets/nbroad/fewnerd). More exactly we use a supervised part of this dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b03e6e6694944aca76f5f72df83b9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7216e51d1a8c41fa9cf4408eb748ebc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f451324e24852afa55561be70cf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 131766\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 18823\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'coarse_tags', 'fine_tags', 'id'],\n",
       "        num_rows: 37647\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fewnerd = load_dataset('json', data_files={\n",
    "    'train': '../fewnerd/supervised/train.json',\n",
    "    'val': '../fewnerd/supervised/dev.json',\n",
    "    'test': '../fewnerd/supervised/test.json',\n",
    "})\n",
    "fewnerd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Loading tag dictionaries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'O', '1': 'art', '2': 'building', '3': 'event', '4': 'location', '5': 'organization', '6': 'other', '7': 'person', '8': 'product'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'art-broadcastprogram',\n",
       " '2': 'art-film',\n",
       " '3': 'art-music',\n",
       " '4': 'art-other',\n",
       " '5': 'art-painting',\n",
       " '6': 'art-writtenart',\n",
       " '7': 'building-airport',\n",
       " '8': 'building-hospital',\n",
       " '9': 'building-hotel',\n",
       " '10': 'building-library',\n",
       " '11': 'building-other',\n",
       " '12': 'building-restaurant',\n",
       " '13': 'building-sportsfacility',\n",
       " '14': 'building-theater',\n",
       " '15': 'event-attack/battle/war/militaryconflict',\n",
       " '16': 'event-disaster',\n",
       " '17': 'event-election',\n",
       " '18': 'event-other',\n",
       " '19': 'event-protest',\n",
       " '20': 'event-sportsevent',\n",
       " '21': 'location-GPE',\n",
       " '22': 'location-bodiesofwater',\n",
       " '23': 'location-island',\n",
       " '24': 'location-mountain',\n",
       " '25': 'location-other',\n",
       " '26': 'location-park',\n",
       " '27': 'location-road/railway/highway/transit',\n",
       " '28': 'organization-company',\n",
       " '29': 'organization-education',\n",
       " '30': 'organization-government/governmentagency',\n",
       " '31': 'organization-media/newspaper',\n",
       " '32': 'organization-other',\n",
       " '33': 'organization-politicalparty',\n",
       " '34': 'organization-religion',\n",
       " '35': 'organization-showorganization',\n",
       " '36': 'organization-sportsleague',\n",
       " '37': 'organization-sportsteam',\n",
       " '38': 'other-astronomything',\n",
       " '39': 'other-award',\n",
       " '40': 'other-biologything',\n",
       " '41': 'other-chemicalthing',\n",
       " '42': 'other-currency',\n",
       " '43': 'other-disease',\n",
       " '44': 'other-educationaldegree',\n",
       " '45': 'other-god',\n",
       " '46': 'other-language',\n",
       " '47': 'other-law',\n",
       " '48': 'other-livingthing',\n",
       " '49': 'other-medical',\n",
       " '50': 'person-actor',\n",
       " '51': 'person-artist/author',\n",
       " '52': 'person-athlete',\n",
       " '53': 'person-director',\n",
       " '54': 'person-other',\n",
       " '55': 'person-politician',\n",
       " '56': 'person-scholar',\n",
       " '57': 'person-soldier',\n",
       " '58': 'product-airplane',\n",
       " '59': 'product-car',\n",
       " '60': 'product-food',\n",
       " '61': 'product-game',\n",
       " '62': 'product-other',\n",
       " '63': 'product-ship',\n",
       " '64': 'product-software',\n",
       " '65': 'product-train',\n",
       " '66': 'product-weapon'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../fewnerd/id2coarse_tags.json\", \"r\") as f:\n",
    "    id2coarse_tag = json.load(f)\n",
    "print(id2coarse_tag)\n",
    "    \n",
    "with open(\"../fewnerd/id2fine_tags.json\", \"r\") as f:\n",
    "    id2fine_tag = json.load(f)\n",
    "id2fine_tag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, [46, 75, 98, 138, 284])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOUTAIN_TAG = 24\n",
    "\n",
    "rows_with_mountain_tag = [i for i, row in enumerate(fewnerd[\"train\"][\"fine_tags\"]) if MOUTAIN_TAG in row]\n",
    "len(rows_with_mountain_tag), rows_with_mountain_tag[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Some examples from the train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'Eighth', 'Army', 'began', 'to', 'attack', 'Italian', 'units', ',', 'located', 'using', 'information', 'from', 'Ultra', ',', 'at', 'Ruweisat', 'Ridge', 'and', 'from', 'again', 'at', 'Tel', 'El', 'Eisa', 'on', '22', 'July', 'and', 'Miteirya', 'Ridge', 'after', 'which', 'another', 'lull', 'fell', '.'], 'coarse_tags': [0, 5, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0], 'fine_tags': [0, 32, 32, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 21, 21, 21, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0, 0, 0], 'id': '46'} \n",
      "\n",
      "{'tokens': ['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'], 'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0], 'fine_tags': [0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0], 'id': '75'} \n",
      "\n",
      "{'tokens': ['Mount', 'Diablo', 'has', 'inspired', 'many', 'artists', 'and', 'writers', '.'], 'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 24, 0, 0, 0, 0, 0, 0, 0], 'id': '98'} \n",
      "\n",
      "{'tokens': ['K2', 'is', 'further', 'north', 'than', 'the', 'Himalayan', 'mountains', 'so', 'the', 'climate', 'is', 'colder', ';', 'the', 'Karakoram', 'range', 'is', 'wider', 'than', 'the', 'Himalayan', 'so', 'more', 'ice', 'and', 'snow', 'is', 'trapped', 'there', '.'], 'coarse_tags': [4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fine_tags': [24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': '138'} \n",
      "\n",
      "{'tokens': ['The', 'North', 'Lyell', 'Mine', ',', 'scene', 'of', 'the', '1912', 'North', 'Mount', 'Lyell', 'Disaster', 'was', 'at', 'its', 'northernmost', 'end', ',', 'on', 'the', 'slopes', 'of', 'Mount', 'Lyell', '.'], 'coarse_tags': [0, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0], 'fine_tags': [0, 11, 11, 11, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 0], 'id': '284'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in fewnerd[\"train\"].select(rows_with_mountain_tag[:5]):\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Replacing tags other than mountain tag with 0, mountain tags with 1, and removing extra columns from new datasets</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b89c55eef14985aa8963d9f33ad218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189480ffb349426caa799495f532a1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256a38292889480b847ef9cbfbf146e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tag_map(tag):\n",
    "    return 1 if tag == MOUTAIN_TAG else 0\n",
    "\n",
    "def tag_list_map(tag_list):\n",
    "    return list(map(tag_map, tag_list))\n",
    "\n",
    "def fine_tags_map(examples):\n",
    "    examples[\"mountain_tags\"] = list(map(tag_list_map, examples[\"fine_tags\"]))    \n",
    "    return examples\n",
    "    \n",
    "fewnerd_mountains = fewnerd.map(fine_tags_map, remove_columns=[\"coarse_tags\", \"fine_tags\", \"id\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Some examples from the processed train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'Eighth', 'Army', 'began', 'to', 'attack', 'Italian', 'units', ',', 'located', 'using', 'information', 'from', 'Ultra', ',', 'at', 'Ruweisat', 'Ridge', 'and', 'from', 'again', 'at', 'Tel', 'El', 'Eisa', 'on', '22', 'July', 'and', 'Miteirya', 'Ridge', 'after', 'which', 'another', 'lull', 'fell', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['Mount', 'Diablo', 'has', 'inspired', 'many', 'artists', 'and', 'writers', '.'], 'mountain_tags': [1, 1, 0, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['K2', 'is', 'further', 'north', 'than', 'the', 'Himalayan', 'mountains', 'so', 'the', 'climate', 'is', 'colder', ';', 'the', 'Karakoram', 'range', 'is', 'wider', 'than', 'the', 'Himalayan', 'so', 'more', 'ice', 'and', 'snow', 'is', 'trapped', 'there', '.'], 'mountain_tags': [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]} \n",
      "\n",
      "{'tokens': ['The', 'North', 'Lyell', 'Mine', ',', 'scene', 'of', 'the', '1912', 'North', 'Mount', 'Lyell', 'Disaster', 'was', 'at', 'its', 'northernmost', 'end', ',', 'on', 'the', 'slopes', 'of', 'Mount', 'Lyell', '.'], 'mountain_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in fewnerd_mountains[\"train\"].select(rows_with_mountain_tag[:5]):\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Computing number of mountain and O tags in processed datasets and their proportion</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset - mountain tags: 4500, O tags: 3223038, proportion: 0.0013961982452580454\n",
      "val   dataset - mountain tags: 734, O tags: 462386, proportion: 0.0015874183041874104\n",
      "test  dataset - mountain tags: 1366, O tags: 919688, proportion: 0.0014852863144892616\n"
     ]
    }
   ],
   "source": [
    "def print_mountain_dataset_stat(name, dataset):\n",
    "    mountain_tags_num = 0\n",
    "    tags_num = 0\n",
    "    for tags in dataset[\"mountain_tags\"]:\n",
    "        mountain_tags_num += sum(tags)\n",
    "        tags_num += len(tags)\n",
    "    o_tags_num = tags_num - mountain_tags_num\n",
    "    print(f\"{name:<5} dataset - mountain tags: {mountain_tags_num}, O tags: {o_tags_num}, proportion: {mountain_tags_num/o_tags_num}\")\n",
    "\n",
    "for k in fewnerd_mountains.keys():\n",
    "    print_mountain_dataset_stat(k, fewnerd_mountains[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load DistilBERT tokenizer to preprocess the tokens field</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cab088e4ff741bb82e43302d7e82a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a7a226400d477ba589ce12805d1724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14170e162064247a2baa3bbab13aceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce578acb9d384ddbbc1d0a9a6761c1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">An example of tokenization in action:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Though', 'only', 'in', 'length', ',', 'The', 'Salamander', 'Glacier', 'is', 'about', 'wide', '.'] \n",
      "\n",
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
      "\n",
      "['[CLS]', 'though', 'only', 'in', 'length', ',', 'the', 'sal', '##aman', '##der', 'glacier', 'is', 'about', 'wide', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example = fewnerd_mountains[\"train\"][\"tokens\"][75]\n",
    "tokenized_input = tokenizer(example, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "print(example, \"\\n\")\n",
    "print(tokenized_input, \"\\n\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Tokenizer adds some special tokens [CLS] and [SEP] and the subword tokenization creates a mismatch between the input and labels. A single word corresponding to a single label may now be split into two subwords. We realign the tokens and labels and remove extra columns from new datasets.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef7b011a092405ea2a8138a67cfa100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0a984e384047e4ba0747e92cbebd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b71b1efc9d949a99a0ba5c1bb84d56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The value that is ignored and does not contribute to the input gradient in CrossEntropyLoss\n",
    "IGNORE_INDEX = -100 \n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"mountain_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) # Map tokens to their respective word\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(IGNORE_INDEX) # Set the special tokens to IGNORE_INDEX\n",
    "            else:\n",
    "                label_ids.append(label[word_idx]) # Label each token of a given word\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "fewnerd_mountains = fewnerd_mountains.map(tokenize_and_align_labels, remove_columns=[\"tokens\", \"mountain_tags\"], batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">An example from the processed train dataset:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2295, 2069, 1999, 3091, 1010, 1996, 16183, 23093, 4063, 10046, 2003, 2055, 2898, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(fewnerd_mountains[\"train\"][75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Set a data collator that will dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Before we start training a model, create a list of lables and dictionaries of label ids and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'location-mountain'] \n",
      "\n",
      "{0: 'O', 1: 'location-mountain'} \n",
      "\n",
      "{'O': 0, 'location-mountain': 1}\n"
     ]
    }
   ],
   "source": [
    "label_list = [id2fine_tag[str(0)], id2fine_tag[str(MOUTAIN_TAG)]]\n",
    "print(label_list, \"\\n\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "print(id2label, \"\\n\")\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load DistilBERT model with AutoModelForTokenClassification along with the number of expected labels, and the label mappings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba4f43dc18945c88544e6cbe31db49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Create a function that computes metrics from predictions and labels, ignoring labels for special tokens</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8e9600deee47c7942fae8ce20424fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != IGNORE_INDEX]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [ [label_list[l] for l in label if l != IGNORE_INDEX] for label in labels ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)    \n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Due to the imbalance of mountain tags number and O tags number in the datasets, we want to use class weights in the loss function. For this we need a customization of Trainer class.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def __init__(self, tag_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tag_weights = tag_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, num_items_in_batch = None, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")       \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')        \n",
    "        \n",
    "        # Compute custom loss\n",
    "        weight=torch.tensor(self.tag_weights)\n",
    "        if torch.cuda.is_available():\n",
    "           weight = weight.cuda()\n",
    "        #    print(\"GPU Activate\")\n",
    "        loss_fun = torch.nn.CrossEntropyLoss(weight)\n",
    "        loss = loss_fun(logits.view(-1, model.config.num_labels), labels.view(-1))        \n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Set parameters for training the model, create an instance of CustomTrainer, train the model, and evaluate it on the test dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_408/1443336891.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCommError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m      5\u001b[39m training_args = TrainingArguments(\n\u001b[32m      6\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33mtrain_output\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     learning_rate=\u001b[32m2e-5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     report_to=\u001b[33m\"\u001b[39m\u001b[33mwandb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m trainer = CustomTrainer(\n\u001b[32m     22\u001b[39m     model=model,\n\u001b[32m     23\u001b[39m     tag_weights=tag_weights,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     compute_metrics=compute_metrics    \n\u001b[32m     30\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m trainer.evaluate(fewnerd_mountains[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2463\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2461\u001b[39m model.zero_grad()\n\u001b[32m   2462\u001b[39m grad_norm: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2463\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.eval_on_start:\n\u001b[32m   2466\u001b[39m     \u001b[38;5;28mself\u001b[39m._evaluate(trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer_callback.py:506\u001b[39m, in \u001b[36mCallbackHandler.on_train_begin\u001b[39m\u001b[34m(self, args, state, control)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[32m    505\u001b[39m     control.should_training_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_begin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer_callback.py:556\u001b[39m, in \u001b[36mCallbackHandler.call_event\u001b[39m\u001b[34m(self, event, args, state, control, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, **kwargs):\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[32m    569\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:930\u001b[39m, in \u001b[36mWandbCallback.on_train_begin\u001b[39m\u001b[34m(self, args, state, control, model, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m     args.run_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._initialized:\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:857\u001b[39m, in \u001b[36mWandbCallback.setup\u001b[39m\u001b[34m(self, args, state, model, **kwargs)\u001b[39m\n\u001b[32m    850\u001b[39m         \u001b[38;5;28mself\u001b[39m._wandb.termwarn(\n\u001b[32m    851\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    852\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    853\u001b[39m             repeat=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    854\u001b[39m         )\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wandb.run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWANDB_PROJECT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;66;03m# add config parameters (run may have been created manually)\u001b[39;00m\n\u001b[32m    862\u001b[39m \u001b[38;5;28mself\u001b[39m._wandb.config.update(combined_dict, allow_val_change=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1595\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings, anonymous)\u001b[39m\n\u001b[32m   1592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wl:\n\u001b[32m   1593\u001b[39m     wl._get_logger().exception(\u001b[33m\"\u001b[39m\u001b[33merror in wandb.init()\u001b[39m\u001b[33m\"\u001b[39m, exc_info=e)\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m \u001b[43mget_sentry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/wandb/analytics/sentry.py:190\u001b[39m, in \u001b[36mSentry.reraise\u001b[39m\u001b[34m(self, exc)\u001b[39m\n\u001b[32m    188\u001b[39m _, _, tb = sys.exc_info()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(exc, \u001b[33m\"\u001b[39m\u001b[33mwith_traceback\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.with_traceback(tb)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1578\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings, anonymous)\u001b[39m\n\u001b[32m   1575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_settings.x_server_side_derived_summary:\n\u001b[32m   1576\u001b[39m     init_telemetry.feature.server_side_derived_summary = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m run = \u001b[43mwi\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1580\u001b[39m \u001b[38;5;66;03m# Set up automatic Weave integration if Weave is installed\u001b[39;00m\n\u001b[32m   1581\u001b[39m weave.setup(run_settings.entity, run_settings.project)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1022\u001b[39m, in \u001b[36m_WandbInit.init\u001b[39m\u001b[34m(self, settings, config, run_printer)\u001b[39m\n\u001b[32m   1008\u001b[39m         result = wait_with_progress(\n\u001b[32m   1009\u001b[39m             run_init_handle,\n\u001b[32m   1010\u001b[39m             timeout=timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1015\u001b[39m             ),\n\u001b[32m   1016\u001b[39m         )\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m   1019\u001b[39m     \u001b[38;5;66;03m# This may either be an issue with the W&B server (a CommError)\u001b[39;00m\n\u001b[32m   1020\u001b[39m     \u001b[38;5;66;03m# or a bug in the SDK (an Error). We cannot distinguish between\u001b[39;00m\n\u001b[32m   1021\u001b[39m     \u001b[38;5;66;03m# the two causes here.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(\n\u001b[32m   1023\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun initialization has timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sec.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m Please try increasing the timeout with the `init_timeout`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1026\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result.run_result\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error := ProtobufErrorHandler.to_exception(result.run_result.error):\n",
      "\u001b[31mCommError\u001b[39m: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`."
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "tag_weights = [0.1, 1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../train_output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tag_weights=tag_weights,\n",
    "    args=training_args,\n",
    "    train_dataset=fewnerd_mountains[\"train\"],\n",
    "    eval_dataset=fewnerd_mountains[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate(fewnerd_mountains[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Save the best model and tokenizer to the specified directory</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../models/fewnerd-mountains-model\"\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ð¡onclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">The model metrics for mountain NER are similar to the BERT metrics for all categories of named entities on supervised [Few-NERD](http://ningding97.github.io/fewnerd) dataset. So it seems that by changing the training parameters we can slightly improve the model performance, but a more significant performance improvement is only available by changing the base model from DistilBERT to another language model, such as RoBERTa or XLNet.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Load the model and tokenizer from the specified path and define a function that tags each word in a text with either the mountain tag or the O tag</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"../models/fewnerd-mountains-model\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Returns a list of word and tag pairs based on the model and tokenizer \n",
    "def get_word_tag_list(text):    \n",
    "    tokenized_input = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "    # Compute a list of predicted tags for all tokens based on the model \n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokenized_input).logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    predicted_tags = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "\n",
    "    # List mapping token IDs to word IDs\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    \n",
    "    # Get a list mapping word IDs to token IDs\n",
    "    word_to_token_ids = []\n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is not None:\n",
    "            if word_id >= len(word_to_token_ids):\n",
    "                word_to_token_ids.append([])\n",
    "            word_to_token_ids[word_id].append(idx)\n",
    "\n",
    "    # Generate a list of word and tag pairs\n",
    "    word_tag_list = []    \n",
    "    for word_id in range(len(word_to_token_ids)):\n",
    "        span = tokenized_input.word_to_chars(word_id)\n",
    "        word = text[span.start:span.end]\n",
    "        \n",
    "        token_id = word_to_token_ids[word_id][0]\n",
    "        tag = predicted_tags[token_id]       \n",
    "        \n",
    "        word_tag_list.append((word, tag))\n",
    "\n",
    "    return word_tag_list     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px\">Examples of the model output:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the model output\n",
    "def print_word_tag_list(text):\n",
    "    word_tag_list = get_word_tag_list(text)\n",
    "    for p in word_tag_list:\n",
    "        print(f\"{p[0]} : {p[1]}\")\n",
    "\n",
    "text = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "The Mont Blanc massif is popular for outdoor activities like hiking, climbing, trail running and winter sports like skiing, and snowboarding.\n",
    "The most popular climbing route to the summit of Mont Blanc is the GoÃ»ter Route, which typically takes two days.\n",
    "\"\"\"\n",
    "print_word_tag_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mont Blanc is a beautiful rooftop cafe.\"\n",
    "print_word_tag_list(text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1383328,
     "sourceId": 2297849,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
